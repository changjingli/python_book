# 后记

![images/010.png](images/010.png "旧时代")

## 写作过程

工作之后，我建立了个人博客，开始与网友们分享一些技术文章，内容多是围绕 LabVIEW 编程语言的。2009 年，我把这部分内容编撰成书出版发行。之后几年我也在继续维护这本书，进行了改版扩充。不过再之后，互联网的管控越来越严格，很多境外网站被屏蔽，也包括我的博客。而我由于没有国内手机号，很多国内的网站也都无法登录留言了。与网友交流越来越少，我也有很长时间失去了写作的动力。

直到 2021 年，从网友那了解到，GitHub 上建站正在成为分享知识的重要途径，尤其难能可贵的是，它居然还没有被国内屏蔽。于是我把那本 LabVIEW 的书搬到了 GitHub 上进行维护（<https://lv.qizhen.xyz/>）。可是，我已经很多年没用 LabVIEW 了，有时候写作起来也感觉力不从心。毕竟，目前工作中主要都在使用 Python，于是我想，也写一写 Python 吧。

我的计划是先集中精力，快速写一个草稿：把最主要的内容都包括进去，不用很全，结构可以不合理，语言也许不通畅，大致的框架打好就行。之后，再是长时间的慢慢维护改进。每次新学到一些知识，也要更新更新。我是 2023 年 10 月份产生这个想法的，只用了一个月的时间就完成了草稿。考虑到我只能利用业余时间写作，一个月的时间是非常神速得了。对比我之前写作 LabVIEW 语言，我觉得如果完成同样写作数量，至少需要多花费二到三被的时间。这与 LabVIEW 这门语言本身不利于写作有关，但更主要的是因为我这次利用了大语言模型来辅助写作。

## 大语言模型

作为技术爱好者，这几年一直在关注 OpenAI 发布的各种新模型。当他们宣布在 GPT 3 中发布了程序生成功能，我就立刻和几个朋友们一起尝试了一下。具体测试了什么问题记不清了，反正是网上随便搜了一个编程面试题目，那个问题有一个实现简单但时间复杂度高的算法，和一个实现困难，但时间复杂度低的算法。我们就把原问题的说明原封不动复制给 GPT，它立刻给出了那个简单直观的算法的代码。再问它是否可以降低时间复杂度，它又给出了一大篇代码。把它的结果放在编译器中一试，完全正确。我们大为震惊，我和朋友们都是程序员，十分担心自己饭碗不保。

朋友眼见，发现 GPT 给出的结果程序，虽然正确，但里面有个变量的名字又长又怪异，非常不常见。于是用这个变量名在 Google 中一搜，果然找到了某网友公开发表的那道面试题的解法。我和同事常出一口气，原来 GPT 还是抄的结果。在用一些网上不太可能找到问题问它，果然答案就差多了。然而，我们并没有安心太久，OpenAI 后来又发布了 ChatGPT，编程能力大为提高。至少，在面试这一块吧，我是怎么也比不过电脑了。除了 OpenAI 的 ChatGPT,我也试了 Google 的 Bard 和 Meta 的 LLAMA。本来也想测试一下国内几个大公司的中文模型，可惜他们都屏蔽了国外用户，我没发用。科技的发展，让我们这些程序员每天都提心吊胆。

“如果战胜不了，就加入他们”。我决定看看能不能用大预言模型来帮我做点什么。除了零零散散做一些测试，我在写这本书的时候也有意识的最大化利用了大语言模型。我利用大模型帮我：
* 列出内容提纲，比如介绍数据类型，我就会让模型列出所有数据类型，然后从中挑选重要的加入书中。
* 编写示例程序，给出需求，模型基本可以编写出差不多的代码。有时可能需要再改进一下，但比完全手写可是省事多了。

大语言模型对于写作的帮助真的是太可观了，极大缩短了我完成本书的时间。单从另一个角度考虑，它也让写作变得不值钱了。如果原本需要三个月的工作，现在一个月就能完成，那么这样工作的价值基本上也就只有原来的三分之一了。可以预想，将来的互联网会充斥着各种 AI 生成的文章、图片、视频，内容极大丰富，价值确极低。

现在的大语言模型还不是万能的，它的创作依然局限于对已有内容的整理拼接，它并不能真正创造出全新的内容。就比如写程序，它极其擅长解决各种面试题目，因为类似内容网上有丰富资源。但是让它完成一个任务崭新的任务，它往往就无法给出满意结果了。写作一时一样，编写入门教程，它手到擒来；总结真实项目里积累的经验，它就无能为力了。从这方面来看，这一轮以大语言模型为代表的 AI 新进展，可能会淘汰一些初级程序员、初级写手、初级画师等等。但问题是，那些高级的程序员也是从新手开始练起的，如果初级职位不存在了，将来没有了新手，又怎么会继续产生高级人才呢。

## 程序员会被淘汰吗？

近期来看，程序员应该还会是最容易找工作的行业之一。AI 的普及不但不会立刻取代已有程序员，反而，训练和部署 AI 模型也是需要程序员来操作的。但是从长远来看，当 AI 发展的一个方向，必然是使用自然语言来替代机器语言。到时候，任何人，只要会说话，就可以操作计算机做任何事情。到时候，只有一些最顶层的模块还需要程序员来维护，高层的应用恐怕都不再需要专业程序员的参与了。

我也不知道那一天何时到来，不过我应该不用太担心，那时候我可能已经退休了。


## AI 会有意识吗？

如果结论是人工智能就快有会意识，就要替代人类了，那么这个话题总会吸引很多人。也难怪机器威胁论（当前是智能机器威胁论）每个十来年就被热炒一番。不过我的观点还是比较保守的，我相信至少在我们有生之年，是不会看到这一天的。甚至人类自己都不知道意识是个什么东西，又怎么能去判断其它物种有没有意识。现在讨论人工智能与意识，很容易就会脱离技术问题，去争论“意识”本身了。

支持 AI 很快就将要“觉醒”的人主要有两个论据，一是 AI 是对人脑的模拟，所以应该可以具有与人类似的意识。的确人脑是神经元构成的，人工神经网络模型也是由“神经元”构成的。但是，人工神经网络模型的神经元与人脑中的神经元可完全不是一回事。比如最基本的，人脑的神经网络是动态的，神经元之间可以新建连接，也可以断掉已有的连接；但人工神经网路的结构是静态的，训练之前就固定下来了。结构也大为不同：人脑的神经元是真正网状连接的，而人工神经网路其实主要是分层连接的。实际上，我们对人脑的了解也还非常有限，还没有完全弄清楚人脑的运行机制。人脑有神经元，并不意味着人的“意识”就只有神经元参与，有些学者就认为量子效应也参与了人的思维活动。人类发现量子效应还不到一百年，也许还有很多人类尚未发现的物理规律也参与了思维活动。这些都是目前人工智能算法完全不具备的，以当前人工智能的简单结构模拟人脑还差的太远。

另一个论据是认为人工神经网路的参数太多了，如此多的参数，说不定它自己突然灵光一现，就产生了自我意识呢？这个想法是把 AI 当魔法了。目前的人工智能算法完全基于严格的数据推力和运算，不具备任何魔法能力。让它出现意识，还要依赖人类的主动设计。指望 AI 自己觉醒，就有点类似于，把组成生命的各种化学物质放到一个瓶子里，然后晃一晃瓶子，就指望里面的分子自己重新排列，构建一个生命体出来。我们有时候会有一些美好的愿望，希望自己并不了解的东西可以自发的产生魔法和奇迹。但是最终这些愿望基本都会落空。


总之，我对于目前人工智能的发展感到非常欣喜，但说到让它发展出与人类相似的智能能力，可能还差着好几轮技术革命呢。


